üîç Running test: Qwen/Qwen2.5-Coder-32B-Instruct | Task: mutant_generation | Best: role_prompting vs Other: thread_of_thought

1. **Focused Output**: Role prompting directs the model to provide only the mutated code, avoiding unnecessary explanations or breakdowns. This focus ensures the response is concise and directly relevant to the task, leading to higher quality and more accurate mutants.

2. **Contextual Understanding**: By assigning a specific role (e.g., Software Architect, Senior Software Engineer, Quality Assurance Engineer), the model better understands the context and expectations of the task. This role-specific context helps the model generate mutants that are semantically altered but syntactically correct, improving the quality of the output.

3. **Minimal Distraction**: Thread of thought prompts encourage a detailed, step-by-step analysis, which can introduce distractions and lead to changes that go beyond small semantic alterations. Role prompting, on the other hand, keeps the model focused on the task at hand, reducing the likelihood of introducing unrelated or excessive modifications.üîç Running test: deepseek-ai/DeepSeek-V3 | Task: mutant_generation | Best: exemplar_selection_knn vs Other: sg_in_context_learning

1. **Contextual Relevance**: The exemplar_selection_knn technique selects the most similar code examples using a k-nearest neighbor approach, ensuring that the provided examples are highly relevant to the target code. This relevance helps the model understand the specific patterns and mutations needed, leading to more accurate and contextually appropriate mutants. In contrast, sg_in_context_learning generates examples automatically, which may not always align closely with the target code's structure or semantics.

2. **Consistency in Mutations**: By leveraging similar code examples, exemplar_selection_knn ensures that the mutations applied are consistent with the patterns observed in the provided examples. This consistency results in mutants that are syntactically correct and semantically meaningful. On the other hand, sg_in_context_learning might introduce variations that deviate from the expected mutation patterns, leading to less reliable or less useful mutants.

3. **Precision in Instructions**: The exemplar_selection_knn technique often pairs the examples with clear, task-specific instructions (e.g., "Output solely the mutated code"), which guides the model to produce focused and precise responses. In contrast, sg_in_context_learning may use more generic or verbose instructions (e.g., marking code as 'Original' and 'Mutant'), which can dilute the model's focus and result in less precise or overly verbose outputs.üîç Running test: meta-llama/Llama-3.3-70B-Instruct-Turbo | Task: mutant_generation | Best: exemplar_selection_knn vs Other: sg_in_context_learning

1. **Contextual Relevance**: The exemplar_selection_knn technique performs better because it selects the most similar code examples to enrich the prompt context, making the provided examples more relevant to the task of mutant generation. This relevance helps the model understand the subtle changes required for mutant generation. As a result, the model can generate more accurate and context-specific mutants.
2. **Focused Guidance**: The exemplar_selection_knn technique offers more focused guidance by providing examples that are closely related to the task, allowing the model to learn from these examples and generate mutants that are more likely to be correct. In contrast, sg_in_context_learning may generate more generic or less relevant examples, leading to poorer performance. This focused guidance enables the model to produce higher-quality mutants.
3. **Reduced Ambiguity**: The exemplar_selection_knn technique reduces ambiguity in the prompt by providing clear and relevant examples, which helps the model to better understand the task requirements and generate mutants that meet these requirements. In contrast, sg_in_context_learning may introduce more ambiguity, leading to mutants that are less accurate or less relevant to the task. By reducing ambiguity, the exemplar_selection_knn technique enables the model to produce more accurate and effective mutants.üîç Running test: o3-mini-2025-01-31 | Task: mutant_generation | Best: role_prompting vs Other: universal_self_consistency

1. Clear Role Alignment: When the model adopts a specific persona (like a Quality Assurance Engineer), it is primed to focus on domain-specific considerations and deliver precise code mutations. This role alignment streamlines the decision-making process, ensuring clarity and relevance in the generated mutant code.

2. Task-Focused Directives: Role prompting delivers clear, succinct instructions that emphasize the code mutation task without extraneous reasoning. This directness leads the model to produce concise, high-quality outputs that adhere strictly to the requirements, resulting in fewer deviations from the intended behavior.

3. Reduced Cognitive Aggregation: Universal self-consistency involves synthesizing multiple responses to form a consensus, which can dilute focus and introduce inconsistencies. In contrast, role prompting prompts the model to provide one targeted answer, thereby minimizing overhead and ensuring that the response closely aligns with subtle mutation objectives.